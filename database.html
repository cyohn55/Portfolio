<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Python Programming</title>
    <!-- Link to CSS -->
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Code(Yohn's) Portfolio</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <a href="bouncingball.html" target="_self"></a>
                <a href="codeexample.html"></a>
                <a href="algorithms.html"></a>
                <a href="hardwarearchitecture.html"></a>
                <a href="database.html"></a>
                <a href="webperformance.html"></a>
                <!-- Add more navigation links as needed -->
            </ul>
        </nav>
    </header>

    <div class="content">
        <!-- Responsive Video Container -->
        <div class="video-container">
            <iframe src="https://www.youtube.com/embed/SK4H5tTT6-M?autoplay=1&loop=1&playlist=SK4H5tTT6-M&mute=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>

    <!-- Written Section -->
    <div class="wrap-text-container">
            
    <p><strong>Normalization is one of the important processes while designing databases. Normalization is actually a technique for reviewing the database design and it includes a set of mathematical rules. Answer the following questions using specific examples:</strong></p>
    
    <p><strong>Does normalization always lead to a good design? Why or why not?</strong></p>
        <p>The process of normalization is a necessary step in database design. Normalization is composed of six normal forms, each higher form aims to further refine and format data attributes of the previous form by filtering, deleting, and abstracting relevant data into relational tables. According to Sharma et al. (2008), "Functional dependencies between attributes of a table guide us on how best to decompose these tables." A functional dependency can be defined as a relationship between attributes (columns) within a relational database table. It specifies how the values of one or more attributes determine the values of other attributes. Each phase of the normalization process attempts to deobfuscate data into meaningful tables, and further define relationships between data in a closure set. (Sharma et al., 2008).</p>
    
    <p><strong>Disadvantages of Normalization</strong></p>
        <p>Although the main goal of normalization is to "clean" and format data so we can make use of it, its implementation isn't straightforward. Below are some of the issues introduced with data normalization:</p>
        <p>
            <ul>
                <li>Normalization asks that we understand what the user requirements are before building the database. The user may not have the domain knowledge needed to specify database requirements to the degree to which the developer needs them.</li>
                <li>The process of defining functional dependencies and closure sets is time-consuming and each higher normal form requires more time.</li>
                <li>Performance issues can arise if we over-decompose the database. As the database is split into smaller abstractions, performance overhead increases due to the need for additional join operations for each closure set.</li>
                <li>Normalization introduces anomalies when performing Insertion, Deletion, and Update functions on a dataset across multiple tables.</li>
            </ul>
        </p>
    
    <p>A real-world example of normalization that I personally experienced was when I worked at an energy brokerage company. Our job was to sell electricity and natural gas contracts, energy efficiency projects, and solar arrays to commercial businesses. We obtained a list of potential customers from each utility provider within our jurisdiction, which typically came in an Excel spreadsheet per utility each month. The difficulty was each utility had many similar customer attributes like service address, billing address, account number, electricity usage in watts, etc., but other utilities had different attributes and none were formatted in the same manner. Additionally, Excel was constrained by the amount of data that could be stored in one spreadsheet and we needed to upload new data to Salesforce, our sales platform, once per month. With each monthly upload, we introduced an update anomaly where we were inadvertently creating hundreds of thousands of duplicates every month we uploaded new data. Finally, a single electricity customer like Walmart might be spread across several utilities. So, to normalize our data into one cohesive format across all utilities, we used Microsoft Access. We also came up with procedures that ensured we wouldn't upload new duplicate customer accounts, instead, we would update the existing accounts.</p>
    <p>In summary, normalization is a process of deleting, formatting and decomposing data attributes into meaningful tables. The aim of normalization is to assign relationships to related attributes of a data set. Although normalization attempts to guide us towards good database design principles, it's heavily reliant on domain knowledge for its implementation, it's a time-consuming process, over decomposition leads to performance issues, and anomalies, such as Insertion, Deletion, and Update can be introduced. Therefore, we should view normalization as a vital part of the process because it promotes good practices in database design, however, the successful implementation of normalization determines whether a design is "good" or "bad," not the process itself.</p>
    
    <p><strong>What kind of issues, and problems are possible in the normalization process?</strong></p>
        <p>Update, deletion, and insertion anomalies are a few issues that can be introduced during the normalization process. Insertion anomalies occur when we attempt to create a data record that is incomplete, where completeness is a requirement. Deletion anomalies arise when deleting a record causes a loss in unrelated data that was part of a record. Finally, update anomalies are like the one I've described above where updating a record, may inadvertently cause redundant data elsewhere in the table.</p>
        <p>Additionally, as we normalize the data to higher and higher forms, performance issues can arise and even more so as the depth and breadth of the amount of data increases. Normalization can also introduce lossy decompositions instead of lossless ones. Sharma et al. (2008)., describe lossy versus lossless decomposition by saying, "Decomposition of a relation R into relations X and Y is lossless if no information from the original relation is lost after the decomposition. In other words, the original relation can be constructed back from the decomposed relations, and no spurious rows of information are added as data to the resulting rows. It follows then, that if a decomposition results in loss of information from the original relation R then the decomposition is lossy and is obviously not a desirable property."</p>
    
        <p><strong>References</strong></p>
        <p>javaTpoint. (2023). Normalization. javaTpoint. https://www.javatpoint.com/dbms-normalization</p>
        <p>Sharma, N., Perniu, L., Chong, R. F., Iyer, A., Nandan, C., Mitea, A. C., Nonvinkere, M., & Danubianu, M. (2010). Databases fundamentals. https://my.uopeople.edu/pluginfile.php/1708888/mod_book/chapter/440708/Database_Fundamentals.pdf</p>     
    </div>
    </div>
</body>
</html>